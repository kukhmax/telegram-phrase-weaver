import os
import hashlib
import json
import logging
from typing import Optional
import google.generativeai as genai

from .utils import redis_client
from ..core.config import get_settings

settings = get_settings()

# –û–±–Ω–æ–≤–ª–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –∏—Å—Ö–æ–¥–Ω–æ–π —Ñ—Ä–∞–∑—ã
PROMPT_TEMPLATE = """
Your task is to help with language learning.
Given:
- Original phrase: "{phrase}" 
- Keyword to focus on: "{keyword}"
- Language: "{language}"
- Target language for translation: "{target_language}"

Please:
1. Create an English search query (1-2 words) for finding an image that best visually represents the keyword "{keyword}". Call this field "image_query".
2. Take the original phrase "{phrase}" and provide its accurate translation to {target_language}. In the original phrase, wrap the keyword "{keyword}" (in any of its forms) with HTML tags <b> and </b>.
3. Create a gap-fill version of the original phrase by replacing EXACTLY the keyword "{keyword}" (or its grammatical form that appears in the phrase) with "_____" (5 underscores). IMPORTANT: Replace only the specific word that corresponds to "{keyword}", not any other words. Call this "gap_fill".
4. Generate 5 additional realistic example sentences using the keyword "{keyword}" in different grammatical forms (conjugations, declensions, etc.).
5. For each of the 5 additional examples, provide accurate translations to {target_language}.
6. In each of the 5 additional examples, find and wrap the keyword "{keyword}" (in any of its forms) with HTML tags <b> and </b>.
7. For each of the 5 additional examples, create a gap-fill version by replacing EXACTLY the keyword "{keyword}" (or its grammatical form) with "_____" (5 underscores). IMPORTANT: Replace only the specific word that corresponds to "{keyword}", not any other words. Call this "gap_fill".

Return ONLY a valid JSON object without any other words or formatting.
Format example:
{{
  "image_query": "walking home sunset",
  "original_phrase": {{"original": "Eu estou <b>indo</b> para casa.", "translation": "–Ø –∏–¥—É –¥–æ–º–æ–π.", "gap_fill": "Eu estou _____ para casa."}},
  "additional_examples": [
    {{"original": "Eles <b>v√£o</b> para a praia.", "translation": "–û–Ω–∏ –∏–¥—É—Ç –Ω–∞ –ø–ª—è–∂.", "gap_fill": "Eles _____ para a praia."}},
    {{"original": "N√≥s <b>fomos</b> ao cinema.", "translation": "–ú—ã –ø–æ—à–ª–∏ –≤ –∫–∏–Ω–æ.", "gap_fill": "N√≥s _____ ao cinema."}},
    {{"original": "Ela <b>vai</b> trabalhar.", "translation": "–û–Ω–∞ –∏–¥–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å.", "gap_fill": "Ela _____ trabalhar."}},
    {{"original": "Voc√™s <b>foram</b> embora.", "translation": "–í—ã —É—à–ª–∏.", "gap_fill": "Voc√™s _____ embora."}},
    {{"original": "Eu <b>irei</b> amanh√£.", "translation": "–Ø –ø–æ–π–¥—É –∑–∞–≤—Ç—Ä–∞.", "gap_fill": "Eu _____ amanh√£."}}
  ]
}}
"""

async def generate_examples_with_ai(phrase: str, keyword: str, language: str, target_language: str) -> Optional[dict]:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–∏–º–µ—Ä—ã —Ñ—Ä–∞–∑ —Å –ø–æ–º–æ—â—å—é AI, –≤–∫–ª—é—á–∞—è –∏—Å—Ö–æ–¥–Ω—É—é —Ñ—Ä–∞–∑—É –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–∏–º–µ—Ä—ã.
    """
    
   # –ö–ª—é—á –∫—ç—à–∞: hash –æ—Ç phrase + keyword –¥–ª—è uniqueness
    cache_key = f"ai:{hashlib.md5((phrase + keyword).encode()).hexdigest()}"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (async get) —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ Redis
    try:
        cached = await redis_client.get(cache_key)
        if cached:
            logging.info(f"AI data loaded from cache for '{phrase}'")
            return json.loads(cached)
    except Exception as e:
        logging.warning(f"Redis connection failed, proceeding without cache: {e}")
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∫—ç—à–∞ ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏ (–∫–∞–∫ –≤ –æ—Ä–∏–≥–∏–Ω–∞–ª–µ)

    try:
        api_key = settings.GOOGLE_API_KEY
        if not api_key or api_key.strip() == "":
            logging.error("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–ª—é—á GOOGLE_API_KEY –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            return {"error": "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω API –∫–ª—é—á"}
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-1.5-flash')
        logging.info(f"Google AI –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è —Ñ—Ä–∞–∑—ã '{phrase}'")
    except AttributeError:
        logging.error("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–ª—é—á GOOGLE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö!")
        return {"error": "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç API –∫–ª—é—á –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Gemini API: {e}")
        return {"error": f"AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –æ—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ - {str(e)}"}
    
    if not model:
        return None

    prompt = PROMPT_TEMPLATE.format(
        phrase=phrase,
        keyword=keyword, 
        language=language, 
        target_language=target_language
    )
    logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ AI-–∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Ñ—Ä–∞–∑—ã '{phrase}' —Å –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º '{keyword}'...")

    try:
        response = await model.generate_content_async(prompt)
        
        if not response or not response.text:
            logging.error(f"AI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è —Ñ—Ä–∞–∑—ã '{phrase}'")
            return {"error": "AI —Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç"}
        
        raw_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –î–õ–Ø –û–¢–õ–ê–î–ö–ò
        logging.info(f"üîç –ü–û–õ–ù–´–ô –°–´–†–û–ô –û–¢–í–ï–¢ GEMINI –¥–ª—è '{phrase}':")
        logging.info(f"üìÑ RAW JSON: {raw_text}")
        logging.info(f"üìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        try:
            data = json.loads(raw_text)
            logging.info(f"‚úÖ JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –¥–ª—è '{phrase}'")
            logging.info(f"üîë –ö–ª—é—á–∏ –≤ JSON: {list(data.keys())}")
        except json.JSONDecodeError as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç–≤–µ—Ç–∞ AI –¥–ª—è '{phrase}': {e}")
            logging.error(f"üîç –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {raw_text[:500]}")
            logging.error(f"üîç –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {raw_text[-200:]}")
            return {"error": "AI —Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö"}
        
        logging.info(f"üéâ AI —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –¥–∞–Ω–Ω—ã–µ –¥–ª—è '{phrase}'.")
        
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–•
        logging.info(f"üìä –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ JSON –¥–ª—è '{phrase}':")
        
        if 'image_query' in data:
            logging.info(f"üñºÔ∏è Image query: '{data['image_query']}'")
        
        if 'original_phrase' in data:
            orig = data['original_phrase']
            logging.info(f"üìù Original phrase:")
            logging.info(f"   - original: '{orig.get('original', 'N/A')}'")
            logging.info(f"   - translation: '{orig.get('translation', 'N/A')}'")
            logging.info(f"   - gap_fill: '{orig.get('gap_fill', 'N/A')}'")
        
        if 'additional_examples' in data:
            examples = data['additional_examples']
            logging.info(f"üìö Additional examples ({len(examples)} —à—Ç—É–∫):")
            for i, example in enumerate(examples[:3]):  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–µ—Ä–≤—ã–µ 3
                logging.info(f"   [{i+1}] original: '{example.get('original', 'N/A')}'")
                logging.info(f"   [{i+1}] translation: '{example.get('translation', 'N/A')}'")
                logging.info(f"   [{i+1}] gap_fill: '{example.get('gap_fill', 'N/A')}'")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        missing_fields = []
        if 'image_query' not in data: missing_fields.append('image_query')
        if 'original_phrase' not in data: missing_fields.append('original_phrase')
        if 'additional_examples' not in data: missing_fields.append('additional_examples')
        
        if missing_fields:
            logging.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è –≤ JSON: {missing_fields}")
        else:
            logging.info(f"‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ JSON")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (async set, TTL 7 –¥–Ω–µ–π = 604800 —Å–µ–∫)
        try:
            cache_saved = await redis_client.set(cache_key, json.dumps(data), ex=604800)
            if cache_saved:
                logging.info(f"üíæ –î–∞–Ω–Ω—ã–µ –¥–ª—è '{phrase}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
        except Exception as cache_error:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à: {cache_error}")
        
        return data
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å AI –¥–ª—è —Ñ—Ä–∞–∑—ã '{phrase}': {e}")
        return {"error": f"–û—à–∏–±–∫–∞ AI —Å–µ—Ä–≤–∏—Å–∞: {str(e)}"}

if __name__ == "__main__":
    asyncio.run(generate_examples_with_ai('my dog', 'dog', 'en', 'pt'))
