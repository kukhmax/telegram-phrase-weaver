import asyncio
import logging
import hashlib
import json
from typing import Optional
import google.generativeai as genai

from .utils import redis_client
from ..core.config import get_settings
from .image_finder import find_image_via_api
from .enrichment import download_and_save_image

settings = get_settings()

# –£–ø—Ä–æ—â–µ–Ω–Ω—ã–π –ø—Ä–æ–º–ø—Ç –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–æ–ª—å–∫–æ –æ–¥–Ω–æ–π —Ñ—Ä–∞–∑—ã
SIMPLE_PHRASE_PROMPT = """
Your task is to help with language learning by creating a single phrase.
Given:
- Original phrase: "{phrase}" 
- Keyword to focus on: "{keyword}"
- Language: "{language}"
- Target language for translation: "{target_language}"

Please:
1. Create an English search query (1-2 words) for finding an image that best visually represents the keyword "{keyword}". Call this field "image_query".
2. Take the original phrase "{phrase}" and provide its accurate translation to {target_language}. In the original phrase, wrap the keyword "{keyword}" (in any of its forms) with HTML tags <b> and </b>.
3. In the translation, also wrap the translated keyword with HTML tags <b> and </b>.

Return ONLY a valid JSON object without any other words or formatting.
Format example:
{{
  "image_query": "walking home sunset",
  "phrase": {{
    "original": "Eu estou <b>indo</b> para casa.",
    "translation": "–Ø <b>–∏–¥—É</b> –¥–æ–º–æ–π."
  }}
}}
"""

async def generate_simple_phrase_with_ai(phrase: str, keyword: str, language: str, target_language: str) -> dict:
    """
    –ì–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç –ø—Ä–æ—Å—Ç—É—é —Ñ—Ä–∞–∑—É —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º —Å –ø–æ–º–æ—â—å—é AI.
    """
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –µ—Å–ª–∏ —ç—Ç–æ development —Ä–µ–∂–∏–º —Å dummy –∫–ª—é—á–æ–º
    if settings.GOOGLE_API_KEY == "dummy_key_for_dev" or settings.ENVIRONMENT == "development":
        logging.info(f"üîß Development mode: returning mock data for phrase '{phrase}'")
        return {
            "image_query": f"{keyword} concept",
            "phrase": {
                "original": f"{phrase.replace(keyword, f'<b>{keyword}</b>')}",
                "translation": f"–ü–µ—Ä–µ–≤–æ–¥: {phrase.replace(keyword, f'<b>{keyword}</b>')}"
            },
            "audio_url": None,
            "image_url": None,
            "image_path": None
        }
    
    # –ö–ª—é—á –∫—ç—à–∞: hash –æ—Ç phrase + keyword + "simple" –¥–ª—è uniqueness
    cache_key = f"ai_simple:{hashlib.md5((phrase + keyword + 'simple').encode()).hexdigest()}"
    
    # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫—ç—à (async get) —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –æ—à–∏–±–æ–∫ Redis
    try:
        cached = await redis_client.get(cache_key)
        if cached:
            logging.info(f"Simple AI data loaded from cache for '{phrase}'")
            return json.loads(cached)
    except Exception as e:
        logging.warning(f"Redis connection failed, proceeding without cache: {e}")
    
    # –ï—Å–ª–∏ –Ω–µ—Ç –∫—ç—à–∞ ‚Äî –Ω–∞—Å—Ç—Ä–æ–π–∫–∞ –º–æ–¥–µ–ª–∏
    try:
        api_key = settings.GOOGLE_API_KEY
        if not api_key or api_key.strip() == "":
            logging.error("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–ª—é—á GOOGLE_API_KEY –ø—É—Å—Ç–æ–π –∏–ª–∏ –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω!")
            return {"error": "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω API –∫–ª—é—á"}
        
        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash-lite')
        logging.info(f"Google AI –º–æ–¥–µ–ª—å —É—Å–ø–µ—à–Ω–æ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–∞ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}'")
    except AttributeError:
        logging.error("–ö–†–ò–¢–ò–ß–ï–°–ö–ê–Ø –û–®–ò–ë–ö–ê: –ö–ª—é—á GOOGLE_API_KEY –Ω–µ –Ω–∞–π–¥–µ–Ω –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∞—Ö!")
        return {"error": "AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç API –∫–ª—é—á –≤ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏"}
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ Gemini API: {e}")
        return {"error": f"AI —Å–µ—Ä–≤–∏—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω: –æ—à–∏–±–∫–∞ –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏–∏ - {str(e)}"}
    
    if not model:
        return None

    prompt = SIMPLE_PHRASE_PROMPT.format(
        phrase=phrase,
        keyword=keyword, 
        language=language, 
        target_language=target_language
    )
    logging.info(f"–û—Ç–ø—Ä–∞–≤–∫–∞ –ø—Ä–æ—Å—Ç–æ–≥–æ AI-–∑–∞–ø—Ä–æ—Å–∞ –¥–ª—è —Ñ—Ä–∞–∑—ã '{phrase}' —Å –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–æ–º '{keyword}'...")

    try:
        response = await model.generate_content_async(prompt)
        
        if not response or not response.text:
            logging.error(f"AI –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}'")
            return {"error": "AI —Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –ø—É—Å—Ç–æ–π –æ—Ç–≤–µ—Ç"}
        
        raw_text = response.text.strip().replace("```json", "").replace("```", "").strip()
        
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –î–õ–Ø –û–¢–õ–ê–î–ö–ò
        logging.info(f"üîç –ü–û–õ–ù–´–ô –°–´–†–û–ô –û–¢–í–ï–¢ GEMINI –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}':")
        logging.info(f"üìÑ RAW JSON: {raw_text}")
        logging.info(f"üìè –î–ª–∏–Ω–∞ –æ—Ç–≤–µ—Ç–∞: {len(raw_text)} —Å–∏–º–≤–æ–ª–æ–≤")
        
        try:
            data = json.loads(raw_text)
            logging.info(f"‚úÖ JSON —É—Å–ø–µ—à–Ω–æ —Ä–∞—Å–ø–∞—Ä—Å–µ–Ω –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}'")
            logging.info(f"üîë –ö–ª—é—á–∏ –≤ JSON: {list(data.keys())}")
        except json.JSONDecodeError as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ JSON –æ—Ç–≤–µ—Ç–∞ AI –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}': {e}")
            logging.error(f"üîç –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI (–ø–µ—Ä–≤—ã–µ 500 —Å–∏–º–≤–æ–ª–æ–≤): {raw_text[:500]}")
            logging.error(f"üîç –°—ã—Ä–æ–π –æ—Ç–≤–µ—Ç AI (–ø–æ—Å–ª–µ–¥–Ω–∏–µ 200 —Å–∏–º–≤–æ–ª–æ–≤): {raw_text[-200:]}")
            return {"error": "AI —Å–µ—Ä–≤–∏—Å –≤–µ—Ä–Ω—É–ª –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö"}
        
        logging.info(f"üéâ AI —É—Å–ø–µ—à–Ω–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–ª –ø—Ä–æ—Å—Ç—É—é —Ñ—Ä–∞–∑—É –¥–ª—è '{phrase}'.")
        
        # –î–ï–¢–ê–õ–¨–ù–û–ï –õ–û–ì–ò–†–û–í–ê–ù–ò–ï –°–¢–†–£–ö–¢–£–†–´ –î–ê–ù–ù–´–•
        logging.info(f"üìä –ê–ù–ê–õ–ò–ó –°–¢–†–£–ö–¢–£–†–´ JSON –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}':")
        
        if 'image_query' in data:
            logging.info(f"üñºÔ∏è Image query: '{data['image_query']}'")
        
        if 'phrase' in data:
            phrase_data = data['phrase']
            logging.info(f"üìù Phrase data:")
            logging.info(f"   - original: '{phrase_data.get('original', 'N/A')}'")
            logging.info(f"   - translation: '{phrase_data.get('translation', 'N/A')}'")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞ –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫ –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ
        missing_fields = []
        if 'image_query' not in data: missing_fields.append('image_query')
        if 'phrase' not in data: missing_fields.append('phrase')
        
        if missing_fields:
            logging.warning(f"‚ö†Ô∏è –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –ø–æ–ª—è –≤ JSON: {missing_fields}")
        else:
            logging.info(f"‚úÖ –í—Å–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç –≤ JSON")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∫—ç—à (async set, TTL 7 –¥–Ω–µ–π = 604800 —Å–µ–∫)
        try:
            cache_saved = await redis_client.set(cache_key, json.dumps(data), ex=604800)
            if cache_saved:
                logging.info(f"üíæ –î–∞–Ω–Ω—ã–µ –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}' —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤ –∫—ç—à")
        except Exception as cache_error:
            logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –≤ –∫—ç—à: {cache_error}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–±—Ä–∞–±–æ—Ç–∫—É –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è
        image_path = None
        if 'image_query' in data and data['image_query']:
            try:
                logging.info(f"üñºÔ∏è –ü–æ–∏—Å–∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞: '{data['image_query']}'")
                image_url = await find_image_via_api(data['image_query'])
                if image_url:
                    image_path = await download_and_save_image(image_url, data['image_query'])
                    if image_path:
                        logging.info(f"‚úÖ –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ —É—Å–ø–µ—à–Ω–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–æ: {image_path}")
                    else:
                        logging.warning(f"‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Å–æ—Ö—Ä–∞–Ω–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –¥–ª—è '{data['image_query']}'")
                else:
                    logging.warning(f"‚ö†Ô∏è –ò–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –¥–ª—è –∑–∞–ø—Ä–æ—Å–∞ '{data['image_query']}'")
            except Exception as img_error:
                logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {img_error}")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –∫ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—é –≤ —Ä–µ–∑—É–ª—å—Ç–∞—Ç
        data['image_path'] = image_path
        
        return data
    except Exception as e:
        logging.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–±–æ—Ç–µ —Å AI –¥–ª—è –ø—Ä–æ—Å—Ç–æ–π —Ñ—Ä–∞–∑—ã '{phrase}': {e}")
        return {"error": f"–û—à–∏–±–∫–∞ AI —Å–µ—Ä–≤–∏—Å–∞: {str(e)}"}